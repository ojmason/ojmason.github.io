<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Erlang on Arguable Intelligence</title>
    <link>https://ojmason.github.io/categories/erlang/index.xml</link>
    <description>Recent content in Erlang on Arguable Intelligence</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-gb</language>
    <copyright>(C) Oliver Mason</copyright>
    <atom:link href="https://ojmason.github.io/categories/erlang/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Solving Combinatory Problems with Erlang</title>
      <link>https://ojmason.github.io/blog/solving-combinatory-problems-with-erlang/</link>
      <pubDate>Sun, 10 May 2015 00:00:00 +0000</pubDate>
      
      <guid>https://ojmason.github.io/blog/solving-combinatory-problems-with-erlang/</guid>
      <description>&lt;p&gt;My daughter had some maths homework the other day:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;You have 4 bags, each full of the numbers 1, 3, 5, and 7 respectively.
Take 10 of the numbers that when added up make 37. What numbers are they?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;So far so good: that sounds easy enough. But a bit of trial and
error quickly leads nowhere. Something can’t be right. So, let’s
get the computer to work it out.&lt;/p&gt;

&lt;p&gt;As I haven’t done much Erlang recently I thought I’d give it a go.
And, during a casual glance at Armstrong’s &lt;em&gt;Programming in Erlang&lt;/em&gt; I
thought I’d finally understood list comprehensions, so I wrote the
following program:&lt;/p&gt;

&lt;pre&gt;
-module(comb).
-export([result/0]).
result() -&gt;
[{A+B+C+D+E+F+G+H+I+J,A,B,C,D,E,F,G,H,I,J}||
A &lt;- [1,3,5,7],
B &lt;- [1,3,5,7],
C &lt;- [1,3,5,7],
D &lt;- [1,3,5,7],
E &lt;- [1,3,5,7],
F &lt;- [1,3,5,7],
G &lt;- [1,3,5,7],
H &lt;- [1,3,5,7],
I &lt;- [1,3,5,7],
J &lt;- [1,3,5,7],
A+B+C+D+E+F+G+H+I+J =:= 37].
&lt;/pre&gt;

&lt;p&gt;I declare a module with one function, &lt;code&gt;result/0&lt;/code&gt;. This finds me ten
variables that can take any of the four specified values and add
up to 37. Simples!&lt;/p&gt;

&lt;p&gt;The list comprehension has ten generators, and one filter; it will
return a tuple with the sum and the individual variables’ values.&lt;/p&gt;

&lt;pre&gt;
Erlang R16B01 (erts-5.10.2) [64-bit] [smp:4:4] [async-threads:10] [hipe] [kernel-poll:false]
Eshell V5.10.2 (abort with ^G)
1&gt; comb:result().
[]
2&gt;
&lt;/pre&gt;

&lt;p&gt;WTF???! An empty list?! So I try changing the 37 to another value, like 36.&lt;/p&gt;

&lt;pre&gt;
3&gt; comb:result().
[{36,1,1,1,1,1,3,7,7,7,7},
{36,1,1,1,1,1,5,5,7,7,7},
{36,1,1,1,1,1,5,7,5,7,7},
{36,1,1,1,1,1,5,7,7,5,7},
{36,1,1,1,1,1,5,7,7,7,5},
[etc, etc].
&lt;/pre&gt;

&lt;p&gt;So it does work! Only, there doesn’t seem to be an answer to the
question. And with a bit of logical reasoning it is obvious: when
adding two odd numbers, you get an even number. So adding ten odd
numbers also yields an even number, but 37 is odd.&lt;/p&gt;

&lt;p&gt;What I learnt from this exercise: thinking about the problem
beforehand can save you time, as there was no need to write a program
at all. But then, I did get to use list comprehensions, and have
learnt how powerful they are. And it neatly shows Erlang’s Prolog
roots as well.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Thinking Erlang, or Creating a Random Matrix without Loops</title>
      <link>https://ojmason.github.io/blog/thinking-erlang-or-creating-a-random-matrix-without-loops/</link>
      <pubDate>Thu, 26 Feb 2009 00:00:00 +0000</pubDate>
      
      <guid>https://ojmason.github.io/blog/thinking-erlang-or-creating-a-random-matrix-without-loops/</guid>
      <description>&lt;p&gt;For a project, my &lt;a href=&#34;https://ojmason.github.io/blog/fast-pfnets-in-erlang/&#34;&gt;Erlang implementation of a fast PFNET algorithm&lt;/a&gt;,
I needed to find a way to create a random matrix of integers (for
path weights), with the diagonal being filled with zeroes.  I was
wondering how best to do that, and started off with two loops, an
inner one for each row, and an outer one for the full set of rows.
Then the problem was how to tell the inner loop at what position
the ‘0’ should be inserted.  I was thinking about passing a row-ID,
when it suddenly clicked: &lt;code&gt;lists:seq/2&lt;/code&gt; was what I needed!  This
method, which I previously thought was pretty useless, creates a
list with a sequence of numbers (the range is specified in the two
parameters).  For example,&lt;/p&gt;

&lt;pre&gt;
1&gt; lists:seq(1,4).
[1,2,3,4]
2&gt; lists:seq(634,637).    
[634,635,636,637]
3&gt; lists:seq(1000,1003).
[1000,1001,1002,1003]
&lt;/pre&gt;

&lt;p&gt;Now I would simply generate a list with a number for each row, and
then send the inner loop off to do its thing, filling the slot given
by the sequence number with a zero, and others with a random value.&lt;/p&gt;

&lt;p&gt;But now it gets even better.  Using a separate (tail-)recursive
function for the inner loop didn’t quite seem right, so I thought
a bit more about it and came to the conclusion that this is simply
a mapping; mapping an integer to a list (a vector of numbers, one
of which (given by the integer) is a zero).  So instead of using a
function for filling the row, I call &lt;code&gt;lists:seq/2&lt;/code&gt; again and then map
the whole thing.  This is the final version I arrived at, and I’m
sure it can still be improved upon using list comprehensions:&lt;/p&gt;

&lt;pre&gt;
random_matrix(Size, MaxVal) -&gt;
  random:seed(),
  lists:map(
    fun(X) -&gt;
      lists:map(
          fun(Y) -&gt;
              case Y of 
                 X -&gt; 0; 
                 _ -&gt; random:uniform(MaxVal)
                 end
              end,
          lists:seq(1,Size))
      end,
    lists:seq(1,Size)).
&lt;/pre&gt;

&lt;p&gt;This solution seems to be far more idiomatic, and I am beginning
to think that I finally no longer think in an imperative way of
loops, but more in the Erlang-way of list operations.  Initially
this is hard to achieve, but with any luck it will become a lot
easier once one is used to it.  Elegance, here I come!&lt;/p&gt;

&lt;p&gt;Example run:&lt;/p&gt;

&lt;pre&gt;
4&gt; random_matrix(6,7).  
[[0,1,4,6,7,4],
 [3,0,5,7,5,4],
 [5,1,0,2,5,2],
 [4,2,4,0,3,1],
 [4,4,3,3,0,1],
 [5,7,3,2,2,0]]
&lt;/pre&gt;

&lt;p&gt;Note: I have used &lt;code&gt;random:seed/0&lt;/code&gt; above, as I am happy for the function
to return identical matrices on subsequent runs with the same
parameters. To get truly random results, that would have to be left
out. However, for my benchmarking purposes it saved me having to
save the matrix to a file and read it in, as I can easily generate
a new copy of the same matrix I used before.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Fast PFNETs in Erlang</title>
      <link>https://ojmason.github.io/blog/fast-pfnets-in-erlang/</link>
      <pubDate>Sat, 14 Feb 2009 00:00:00 +0000</pubDate>
      
      <guid>https://ojmason.github.io/blog/fast-pfnets-in-erlang/</guid>
      <description>

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://en.wikipedia.org/wiki/Pathfinder_Networks&#34;&gt;Pathfinder Networks&lt;/a&gt;
(PFNETs) are networks derived from a graph
representing proximity data.  Basically, each node is connected to
(almost) every other node by a weighted link, and that makes it
hard to see what’s going on.  The Pathfinder algorithm prunes the
graph by removing links which are weighted higher than another path
between the same nodes.&lt;/p&gt;

&lt;p&gt;For example: A links to B with weight 5.  A also links to C with
weight 2, and C links to B with weight 2.  Adding up the weights,
A to B direct is 5, A to C to B is 4.  Result: we remove the link
from A to B, as the route via C is shorter.  There are different
ways to calculate the path lengths (using the &lt;a href=&#34;http://en.wikipedia.org/wiki/Minkowski_metric&#34;&gt;Minkowski &lt;em&gt;r&lt;/em&gt;-metric&lt;/a&gt;),
but you get the general idea.  The resulting PFNET has fewer links
and is easier to analyse.&lt;/p&gt;

&lt;p&gt;In Schvaneveldt (1990) an algorithm for computing PFNETs is given,
but it is rather complex and computationally intensive.  There is
an improved algorithm called Binary Pathfinder, but that is apparently
more memory intensive.  Not very promising so far, but then along
comes &lt;em&gt;A new variant of the Pathfinder algorithm to generate large
visual science maps in cubic time&lt;/em&gt;, by Quirin, Cordón, Santamaría,
Vargas-Quesada, and Moya-Anegón.  This algorithm is a lot faster
(by about 450 times), but has one disadvantage: speed is traded in
for flexibility.  The original Pathfinder algorithm has two parameters,
&lt;em&gt;r&lt;/em&gt; (the value of the Minkowski metric to be used) and &lt;em&gt;q&lt;/em&gt; (the maximum
length of paths to be considered).  The fast algorithm only has &lt;em&gt;r&lt;/em&gt;,
and always uses the maximum value for &lt;em&gt;q&lt;/em&gt; (which is n-1).  I know too
little about the application of PFNETs to say whether this is
important at all; for the uses I can envisage it does not seem to
matter.&lt;/p&gt;

&lt;p&gt;As added bonus, the algorithm in pseudo code in Quirin et al. is
very short and straightforward.  They’re using a different &lt;a href=&#34;http://en.wikipedia.org/wiki/Floyd-Warshall_algorithm&#34;&gt;shortest-path
algorithm&lt;/a&gt;
to identify, erm, shorter paths.  And then it’s very
simple to prune the original network.&lt;/p&gt;

&lt;p&gt;A picture tells more than 1K words, so here instead of 2000 words
the before and after, graph layout courtesy of the graphviz program:&lt;/p&gt;

&lt;p&gt;A network example (from Schvaneveldt 1990)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://ojmason.github.io/img/pfnets-1.png&#34; caption=&#34;Fig 1: A network example (from Schvaneveldt 1990)&#34;/&gt;&lt;/p&gt;

&lt;p&gt;Here, each node is linked to every other node.  Running the PFNET
algorithm on it, we get the output shown in the second figure.&lt;/p&gt;

&lt;p&gt;A PFNET generated from the previous graph&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://ojmason.github.io/img/pfnets-2.png&#34; caption=&#34;Fig 2: A PFNET generated from the previous graph&#34;/&gt;&lt;/p&gt;

&lt;p&gt;If you compare the output with the actual result from Schvaneveldt’s
book (p.6 / 7), you’ll realise that it is not identical, and the
reason for that is that the example there limits the path-length,
using the parameters (&lt;em&gt;r&lt;/em&gt; = 1, &lt;em&gt;q&lt;/em&gt; = 2) rather than (&lt;em&gt;r&lt;/em&gt; = 1, &lt;em&gt;q&lt;/em&gt; = n-1)
as in the example shown here.  As a consequence, the link from N1
to N4 (with a weight of 5) disappears, because of the shorter path
(N1-N2-N3-N4, weight 4).  But that path is too long if &lt;em&gt;q&lt;/em&gt; is just
2, and so it is kept in Schvaneveldt’s example.&lt;/p&gt;

&lt;h2 id=&#34;implementation&#34;&gt;Implementation&lt;/h2&gt;

&lt;p&gt;It is not possible to implement the pseudo-code given in Quirin &lt;em&gt;et
al&lt;/em&gt; directly (in Erlang), as they use destructive updates of the link matrix,
which we obviously cannot do in Erlang.  But the first, naïve,
implementation is still quite short.  The input graph is represented
as a matrix (&lt;em&gt;n&lt;/em&gt; x &lt;em&gt;n&lt;/em&gt;) where each value stands for the link weight,
with zero being used to indicate non-existing links.  I have written
a function that creates a dot file from a matrix, which is then fed
into graphviz for generating images as the ones shown above.&lt;/p&gt;

&lt;p&gt;There are basically two steps: creating a matrix of shortest paths
from the input matrix, and then generating the PFNET by comparing
the two matrices; if a certain cell has the same value in both
matrices, then it is a shortest path and is kept, otherwise there
is a shorter path and it’s pruned. Here is the main function:&lt;/p&gt;

&lt;pre&gt;
find_path(Matrix) -&gt;
    Shortest = loop1(1,length(Matrix),Matrix),
    generate_pfnet(Matrix, Shortest, []).
&lt;/pre&gt;

&lt;p&gt;Next we have the three loops (hence ‘cubic time’!) of the Floyd-Warshall
shortest path algorithm to create the shortest path matrix:&lt;/p&gt;

&lt;pre&gt;
loop1(K,N,Matrix) when K &gt; N -&gt; 
    Matrix;
loop1(K,N,Matrix) -&gt;
    NewMatrix = loop2(K,1,Matrix,
        Matrix,[]),
    loop1(K+1,N,NewMatrix).

loop2(_,_,_,[],Acc) -&gt;
    lists:reverse(Acc);
loop2(K,I,D,[Row|Rest],Acc) -&gt;
    NewRow = loop3(K,I,1,D, Row, []),
    loop2(K,I+1,D,Rest,[NewRow|Acc]).

loop3(_,_,_,_, [], Acc) -&gt;
    lists:reverse(Acc);
loop3(K,I,J,D, [X|Rest], Acc) -&gt;
    loop3(K,I,J+1,D, Rest,
    [min(X, get(I,K,D) + get(K,J,D))|Acc]).
&lt;/pre&gt;

&lt;p&gt;The final line implements the Minkowski metric with &lt;em&gt;r&lt;/em&gt; = 1; this
could be expanded to include other values as well, eg &lt;em&gt;r&lt;/em&gt; = 2 for
Euclidean, or &lt;em&gt;r&lt;/em&gt; = ∞ (which seem to be the most common values in
use; the latter means using the maximum weight of any path component
along the full path).&lt;/p&gt;

&lt;p&gt;And here are two utility methods, one to find the smaller of two
values, and one to retrieve an element from a matrix (which is a
list of rows).  There is something of a hack to deal with the fact
that zero does not mean a very small weight, but refers to a
non-existing link:&lt;/p&gt;

&lt;pre&gt;
min(X, Y) when X &lt; Y -&gt; X;
min(_X, Y) -&gt; Y.

get(Row, Col, Matrix) -&gt;
    case lists:nth(Col,
      lists:nth(Row, Matrix)) of
        0 -&gt; 999999999;
        X -&gt; X
    end.
&lt;/pre&gt;

&lt;p&gt;And finally, generating the PFNET by comparing the two matrices
(again, awful hack included):&lt;/p&gt;

&lt;pre&gt;
generate_pfnet([],[],Result) -&gt;
    lists:reverse(Result);
generate_pfnet([R1|Rest1], [R2|Rest2], Acc) -&gt;
    Row = generate_pfrow(R1,R2,[]),
    generate_pfnet(Rest1, Rest2, [Row|Acc]).

generate_pfrow([],[],Result) -&gt;
    lists:reverse(Result);
generate_pfrow([C|Rest1], [C|Rest2], Acc) -&gt;
    case C of
        999999999 -&gt; C1 = 0;
        _ -&gt; C1 = C
    end,
    generate_pfrow(Rest1, Rest2, [C1|Acc]);
generate_pfrow([C1|Rest1], [C2|Rest2], Acc) -&gt;
    generate_pfrow(Rest1, Rest2, [0|Acc]).
&lt;/pre&gt;

&lt;h2 id=&#34;discussion&#34;&gt;Discussion&lt;/h2&gt;

&lt;p&gt;So this is the basic code.  It works, but there is scope for improvement.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;it only currently generates PFNETs with (&lt;em&gt;r&lt;/em&gt; = 1, &lt;em&gt;q&lt;/em&gt; = &lt;em&gt;n&lt;/em&gt;-1)&lt;/li&gt;
&lt;li&gt;there is no parallelism, hence it’s not really making use of Erlang’s strengths.&lt;/li&gt;
&lt;li&gt;the three loops don’t look very elegant, and could probably be replaced by list comprehensions&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Because of the matrix being updated, it doesn’t look that easy to
parallelise the processing, but it would work at the level of
updating the individual rows.  If that can be done in parallel, it
would probably provide some speed-up (provided the matrix is not
of a trivial size).  So the first step would be to change the matrix
processing using &lt;code&gt;lists:map/2&lt;/code&gt;, and replacing this then by &lt;code&gt;pmap&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Once the code is up to scratch with full parallelism, and tested
on larger matrices I will probably put it up on Google Code in case
other people are interested in using it.  If you have any suggestions,
tell me in the comments!&lt;/p&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;dl&gt;
&lt;dt&gt;Schvaneveldt, R. W. (Ed.) (1990)&lt;/dt&gt;
&lt;dd&gt;Pathfinder Associative Networks: Studies in Knowledge Organization. Norwood, NJ: Ablex.
The book is out of print. A copy can be downloaded from the &lt;a href=&#34;http://en.wikipedia.org/wiki/Pathfinder_Networks&#34;&gt;Wikipedia page&lt;/a&gt;&lt;/dd&gt;
&lt;dt&gt;Quirin, A; Cordón, O; Santamaría, J; Vargas-Quesada, B; Moya-Anegón, F (2008)&lt;/dt&gt;
&lt;dd&gt;“A new variant of the Pathfinder algorithm to generate large visual science maps in cubic time”, Information Processing and Management, 44, p.1611-1623.&lt;/dd&gt;
&lt;/dl&gt;
</description>
    </item>
    
    <item>
      <title>Replacing a stack with concurrency</title>
      <link>https://ojmason.github.io/blog/replacing-a-stack-with-concurrency/</link>
      <pubDate>Wed, 23 Apr 2008 00:00:00 +0000</pubDate>
      
      <guid>https://ojmason.github.io/blog/replacing-a-stack-with-concurrency/</guid>
      <description>&lt;p&gt;For some language processing task I needed a reasonably powerful
parser (a program to identify the syntactic structure of a sentence).
So I dug out my copy of Winograd (1983) (&lt;em&gt;Language as a Cognitive
Process&lt;/em&gt;) and set about implementing an &lt;a href=&#34;https://en.wikipedia.org/wiki/Augmented_transition_network&#34;&gt;Augmented Transition Network&lt;/a&gt;
parser in Erlang.&lt;/p&gt;

&lt;p&gt;Now, the first thing you learn about natural language is that it
is full of ambiguities, and so there will always be several
alternatives available, several possible paths through the network
which defines the grammar. The traditional solution is to dump all
the alternatives on a stack, and look at them when the current path
has been finished with. You can either go depth-first, where you
complete the current path before you get the next one off the stack,
or breadth-first, where you advance all paths by one step at a time,
kind of pseudo-parallel.&lt;/p&gt;

&lt;p&gt;Having to deal with a stack is tedious, as you need to keep track
of the current configuration: which network are you at, what node,
what position in the sentence, etc. But then, it occurred to me,
there’s an easier way to do it (at least it’s easier in Erlang!):
every time you come to a point where you have multiple alternatives,
you spawn a new process and pursue all of them in parallel.&lt;/p&gt;

&lt;p&gt;The only overhead you need is a loop which keeps track of all the
processes currently running. This loop receives the results of
successful paths, and gets notified of unsuccessful ones (where the
process terminates without having found a valid structure). No need
for a stack, and hopefully very efficient processing on multi-core
machines as a free side-effect.&lt;/p&gt;

&lt;p&gt;I’m still amazed how easy it was to implement. I wouldn’t have
fancied doing that in Java or even C. For my test sentences I had
about 8 to 10 processes running in parallel most of the time, but
it depends on the size of the grammar and the length of the sentence
really. What I liked about this was that it seemed the natural way
to do in Erlang, where working with processes is just so easy.&lt;/p&gt;

&lt;p&gt;And also, another nail in the coffin for the claim that you can’t
use Erlang for handling texts easily!&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>